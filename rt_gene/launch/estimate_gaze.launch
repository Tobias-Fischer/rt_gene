<launch>
    <arg name="pytorch_num_threads" default="8" />
    <arg name="use_face_encoding_tracker" default="True" />
    <arg name="face_encoding_threshold" default="0.6"/>
    <arg name="start_rviz" default="False"/>

    <arg name="video_namespace" default="/kinect2/hd"/>
    <arg name="video_image_topic" default="image_color_rect"/>
    <arg name="video_info_topic" default="camera_info"/>

    <arg name="ros_tf_frame" default="/kinect2_nonrotated_link"/>

    <arg name="group_name" default="gaze" />
    <arg name="tf_prefix" default="$(arg group_name)" />
    <arg name="device_id_facedetection"  default="cuda:0" /> <!-- pyTorch format, e.g. cuda:0 or cpu:0 -->
    <arg name="device_id_gazeestimation"  default="/gpu:0" /> <!-- tensorflow format, e.g. /gpu:0 or /cpu:0 -->

    <env name="OMP_NUM_THREADS" value="$(arg pytorch_num_threads)" />
    <env name="KMP_SETTING" value="KMP_AFFINITY=granularity=fine,compact,1,0" />
    <env name="KMP_BLOCKTIME" value="1" />

    <group ns="$(arg group_name)">
      <node pkg="rt_gene" type="extract_landmarks_node.py" name="extract_landmarks_new" output="screen">
          <param name="device_id_facedetection"  value="$(arg device_id_facedetection)" />
          <param name="use_face_encoding_tracker" value="$(arg use_face_encoding_tracker)" />
          <param name="face_encoding_threshold" value="$(arg face_encoding_threshold)" />
          <param name="ros_tf_frame" value="$(arg ros_tf_frame)" />
          <param name="tf_prefix" value="$(arg tf_prefix)" />
          <param name="interpupillary_distance" value="$(arg interpupillary_distance)" />

          <remap from="/camera_info" to="$(arg video_namespace)/$(arg video_info_topic)"/>
          <remap from="/image" to="$(arg video_namespace)/$(arg video_image_topic)"/>
      </node>

      <node pkg="rt_gene" type="estimate_gaze.py" name="estimate_gaze_twoeyes" output="screen">
          <rosparam param="model_files">['model_nets/Model_allsubjects1.h5']</rosparam>
          <!-- rosparam param="model_files">['model_nets/all_subjects_mpii_prl_utmv_0_02.h5', 'model_nets/all_subjects_mpii_prl_utmv_1_02.h5', 'model_nets/all_subjects_mpii_prl_utmv_2_02.h5', 'model_nets/all_subjects_mpii_prl_utmv_3_02.h5']</rosparam-->
          <param name="tf_prefix" value="$(arg tf_prefix)" />/
          <param name="ros_tf_frame" value="$(arg ros_tf_frame)" />
          <param name="device_id_gazeestimation"  value="$(arg device_id_gazeestimation)" />
      </node>      
    </group>

    <node pkg="rviz" type="rviz" name="rviz_test" args="-d $(find rt_gene)/rviz_cfg/gaze_following.rviz" if="$(arg start_rviz)" />
</launch>

